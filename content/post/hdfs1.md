---
title: "HDFS는 어떻게 사용할까요?(1)"
date: 2022-07-13T11:51:42+09:00
categories:
- development
tags:
- development
keywords:
- data engineering, hadoop, development, hdfs
image: elephants-g07073c915_1920.jpg
---

![elephant](https://github.com/shcDE/pictures/blob/main/images_for_blog/elephants-g07073c915_1920.jpg?raw=true)
_________________________________________________________________________________________________________________________________________________________________________
안녕하세요. shcDE입니다. 오늘은 하둡 환경에서 분산 파일 시스템 기능을 담당하는 하둡의 주요 모듈인 HDFS에 대해 다루겠습니다. 이번 포스팅에서는 HDFS의 기능 및 특징 중, 구조, Federation, 고가용성, 세이프모드, 데이터 블록 관리, 그리고 휴지통에 대한 내용을 다루고자 합니다. 해당 내용은 하둡을 설치하였다는 가정 하에 다루겠습니다. 실행 전 참고하실 사항은 Mac OS 환경인 만큼 명령어가 다르다는 점이니 확인해주시길 바랍니다.
_________________________________________________________________________________________________________________________________________________________________________
우선 시작하기 앞서, YARN에서 namenode  deamon, data node daemon, NodeManager daemon, ResourceManager를 실행해야 합니다. 이들을 실행시키지 않을 경우 HDFS를 다룰 수 없습니다. 실행 방법은 다음과 같습니다.
_________________________________________________________________________________________________________________________________________________________________________
우선 하둡 파일을 저장한 경로로 이동합니다.  

```
(base) shcDE-ui-MacBookPro:~ shc$ cd /usr/local/hadoop
(base) shcDE-ui-MacBookPro:hadoop shc$
```
_________________________________________________________________________________________________________________________________________________________________________

다음으로 파일 시스템을 포맷해줍니다. 맥에서 hdfs 명령어를 실행할 때는 hdfs 파일이 있는 경로를(예 : bin/hdfs) 포함하여 입력하면 실행됩니다.
```
$ bin/hdfs namenode -format
```
그리고 namenode  deamon과 data node daemon을 실행시켜줍니다.
```
$ sbin/start-dfs.sh
```
_________________________________________________________________________________________________________________________________________________________________________
![daemon](https://github.com/shcDE/pictures/blob/main/images_for_blog/Screenshot%202022-07-12%20at%2021-43-33%20Namenode%20information.png?raw=true)
_________________________________________________________________________________________________________________________________________________________________________
정상적으로 실행된다면 'http://localhost:9870/' 접속 시 위와 같이 나타납니다.
_________________________________________________________________________________________________________________________________________________________________________
다음으로 ResourceManager와 NodeManager daemon을 다음 명령어를 통해 실행합니다.
_________________________________________________________________________________________________________________________________________________________________________
```
$ sbin/start-yarn.sh
```
_________________________________________________________________________________________________________________________________________________________________________
정상적으로 실행된다면 'http://localhost:8088/' 입력 시 다음과 같이 나타납니다.
_________________________________________________________________________________________________________________________________________________________________________
![Manager](https://github.com/shcDE/pictures/blob/main/images_for_blog/Screenshot%202022-07-12%20at%2021-43-49%20All%20Applications.png?raw=true)
_________________________________________________________________________________________________________________________________________________________________________
이제 본격적으로 HDFS를 다루어 보겠습니다. 우선 HDFS는 마스터 슬레이브 구조로 구성되어 있으며, 이 중에서 블록과 세컨더리 네임노드에 대해 설명드리겠습니다.
_________________________________________________________________________________________________________________________________________________________________________
블록 캐싱을 하는 방법은 다음과 같습니다.
_________________________________________________________________________________________________________________________________________________________________________
캐시 어드민을 확인하는 방법은 다음과 같습니다.  

```
$ bin/hdfs cacheadmin
Usage: bin/hdfs cacheadmin [COMMAND]
          [-addDirective -path <path> -pool <pool-name> [-force] [-replication <replication>] [-ttl <time-to-live>]]
          [-modifyDirective -id <id> [-path <path>] [-force] [-replication <replication>] [-pool <pool-name>] [-ttl <time-to-live>]]
          [-listDirectives [-stats] [-path <path>] [-pool <pool>] [-id <id>]]
          [-removeDirective <id>]
          [-removeDirectives -path <path>]
          [-addPool <name> [-owner <owner>] [-group <group>] [-mode <mode>] [-limit <limit>] [-defaultReplication <defaultReplication>] [-maxTtl <maxTtl>]]
          [-modifyPool <name> [-owner <owner>] [-group <group>] [-mode <mode>] [-limit <limit>] [-defaultReplication <defaultReplication>] [-maxTtl <maxTtl>]]
          [-removePool <name>]
          [-listPools [-stats] [<name>]]
          [-help <command-name>]

Generic options supported are:
-conf <configuration file>        specify an application configuration file
-D <property=value>               define a value for a given property
-fs <file:///|hdfs://namenode:port> specify default filesystem URL to use, overrides 'fs.defaultFS' property from configurations.
-jt <local|resourcemanager:port>  specify a ResourceManager
-files <file1,...>                specify a comma-separated list of files to be copied to the map reduce cluster
-libjars <jar1,...>               specify a comma-separated list of jar files to be included in the classpath
-archives <archive1,...>          specify a comma-separated list of archives to be unarchived on the compute machines

The general command line syntax is:
command [genericOptions] [commandOptions]
```
_________________________________________________________________________________________________________________________________________________________________________
다음과 같이 정상적으로 확인되면 pool을 등록합니다.

```
$ bin/hdfs cacheadmin -addPool pool1
2022-07-12 21:00:30,724 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Successfully added cache pool pool1.
```

여기에서 '2022-07-12 21:00:30,724 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable' 오류가 나올텐데, 이는 맥 OS의 경우 신경쓰지 않으셔도 됩니다. 아래에 'Successfully added cache pool pool1.'와 같이 결과가 출력되면 이상 없이 실행된 것으로 보시면 됩니다.
_________________________________________________________________________________________________________________________________________________________________________
이제 pool이 등록되었으면 path를 등록합니다.

```
$ bin/hdfs cacheadmin -addDirective -path /user/hadoop/shs -pool pool1
2022-07-12 21:01:23,073 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Added cache directive 1
```
_________________________________________________________________________________________________________________________________________________________________________
캐시를 확인하면 정상적으로 pool이 있음을 확인할 수 있습니다.

```
$ bin/hdfs cacheadmin -listDirectives

2022-07-12 21:01:56,554 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable

Found 1 entry

 ID POOL    REPL EXPIRY  PATH             

  1 pool1      1 never   /user/hadoop/shs 
```
_________________________________________________________________________________________________________________________________________________________________________
세컨더리 네임노드, Federation, 고가용성은 문서의 설명을 가져와서 설명드리겠습니다. 우선 [세컨더리 네임노드](https://wikidocs.net/37810)는 다음과 같이 설명되어 있습니다.
_________________________________________________________________________________________________________________________________________________________________________
###### '네임노드가 구동되고 나면 Edits 파일이 주기적으로 생성됩니다. 네임노드의 트랜잭션이 빈번하면 빠른 속도로 Edits 파일이 생성됩니다. 이는 네임노드의 디스크 부족 문제를 생성할 수도 있고, 네임노드가 재구동 되는 시간을 느려지게 할 수도 있습니다.
_________________________________________________________________________________________________________________________________________________________________________
###### 세컨더리 네임노드는 Fsimage와 Edits 파일을 주기적으로 머지하여 최신 블록의 상태로 파일을 생성합니다. 파일을 머지하면서 Edits 파일을 삭제하기 때문에 디스크 부족 문제도 해결 할 수 있습니다. 작동 방식은 다음과 같습니다.'
_________________________________________________________________________________________________________________________________________________________________________
![세컨더리 네임노드](https://charsyam.files.wordpress.com/2011/04/fsimage.png)
_________________________________________________________________________________________________________________________________________________________________________
[Federation](https://wikidocs.net/23624)에 대한 설명은 다음과 같습니다. 
_________________________________________________________________________________________________________________________________________________________________________
###### '네임노드는 파일 정보 메타데이터를 메모리에서 관리합니다. 파일이 많아지면 메모리 사용량이 늘어나게 되고, 메모리 관리가 문제가 됩니다. 이를 해결하기 위해 하둡 v2 부터 HDFS 페더레이션을 지원합니다.
_________________________________________________________________________________________________________________________________________________________________________
###### HDFS 페더레이션은 디렉토리(네임스페이스) 단위로 네임노드를 등록하여 사용하는 것입니다. 예를 들어 user, hadoop, tmp 세개의 디렉토리가 존재할 때, /user, /hadoop, /tmp 디렉토리 단위로 총 3개의 네임노드를 실행하여 파일을 관리하게 하는 것입니다.
_________________________________________________________________________________________________________________________________________________________________________
###### HDFS 페더레이션을 사용하면 파일, 디렉토리의 정보를 가지는 네임스페이스와 블록의 정보를 가지는 블록 풀을 각 네임노드가 독립적으로 관리합니다. 네임스페이스와 블록풀을 네임스페이스 볼륨이라하고 네임스페이스 볼륨은 독립적으로 관리되기 때문에 하나의 네임노드에 문제가 생겨도 다른 네임노드에 영향을 주지 않습니다.'
_________________________________________________________________________________________________________________________________________________________________________
![Federation](https://hadoop.apache.org/docs/r2.7.2/hadoop-project-dist/hadoop-hdfs/images/federation.gif)
_________________________________________________________________________________________________________________________________________________________________________
[고가용성](https://wikidocs.net/23628)에 대한 설명은 다음과 같습니다.
_________________________________________________________________________________________________________________________________________________________________________
###### 'HDFS는 네임노드가 단일 실패 지점입니다. 네임노드에 문제가 발생하면 모든 작업이 중지되고, 파일을 읽거나 쓸수 없게 됩니다. 하둡 v2에서 이 문제를 해결하기 위해서 HDFS 고가용성(High Availability)을 제공합니다.
_________________________________________________________________________________________________________________________________________________________________________
###### HDFS 고가용성은 이중화된 두대의 서버인 액티브(active) 네임노드와 스탠바이(standby) 네임노드를 이용하여 지원합니다. 액티브 네임노드와 스탠바이 네임노드는 데이터 노드로부터 블록 리포트와 하트비트를 모두 받아서 동일한 메타데이터를 유지하고, 공유 스토리지를 이용하여 에디트파일을 공유합니다.
_________________________________________________________________________________________________________________________________________________________________________
###### 액티브 네임노드는 네임노드의 역활을 수행하고, 스탠바이 네임노드는 액티브 네임노드와 동일한 메타데이터 정보를 유지하다가, 액티브 네임노드에 문제가 발생하면 스탠바이 네임노드가 액티브 네임노드로 동작하게 됩니다. 액티브 네임노드에 문제가 발생하는 것을 자동으로 확인하는 것이 어렵기 때문에 보통 주키퍼를 이용하여 장애 발생시 자동으로 변경될 수 있도록 합니다.
_________________________________________________________________________________________________________________________________________________________________________
###### 스탠바이 네임노드는 세컨더리 네임노드의 역할을 동일하게 수행합니다. 따라서 HDFS를 고가용성 모드로 설정하였을 때는 세컨더리 네임노드를 실행하지 않아도 됩니다. 고가용성 모드에서 세컨더리 네임노드를 실행하면 오류가 발생합니다.'
_________________________________________________________________________________________________________________________________________________________________________
'QJM(Quorum Journal Manager)'과 'NFS(Network File System)' 개념까지 추가로 공부하고 싶으신 분들은 [이 링크](https://wikidocs.net/23628)를 클릭해주시면 감사하겠습니다.
_________________________________________________________________________________________________________________________________________________________________________
다음으로 세이프모드 작동 방법은 아래와 같습니다.
_________________________________________________________________________________________________________________________________________________________________________
우선 세이프모드 상태를 확인하겠습니다.
_________________________________________________________________________________________________________________________________________________________________________
```
$ bin/hdfs dfsadmin -safemode get
2022-07-12 21:18:33,865 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Safe mode is OFF
```
위와 같이 OFF임을 확인할 수 있습니다.
_________________________________________________________________________________________________________________________________________________________________________
세이프모드 진입은 다음 명령어를 통해서 할 수 있습니다.
```
$ bin/hdfs dfsadmin -safemode enter

2022-07-12 21:19:31,044 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable

Safe mode is ON
```
_________________________________________________________________________________________________________________________________________________________________________
세이프모드 해제는 다음 명령어를 통해서 할 수 있습니다.
```
$ bin/hdfs dfsadmin -safemode leave
2022-07-12 21:20:03,159 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Safe mode is OFF
```
_________________________________________________________________________________________________________________________________________________________________________
이제 다음으로 데이터 블록 관리 방법에 대해 말씀드리겠습니다. 명령어를 실행했을 때 "The filesystem under path '패스' is HEALTHY"가 나오면 정상이라는 의미입니다.
```
$ bin/hdfs fsck /

2022-07-12 21:30:51,049 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable

Connecting to namenode via http://localhost:9870/fsck?ugi=shc&path=%2F

FSCK started by shc (auth:SIMPLE) from /127.0.0.1 for path / at Tue Jul 12 21:30:51 KST 2022





Status: HEALTHY

 Number of data-nodes:	0

 Number of racks:	0

 Total dirs:	1

 Total symlinks:	0



Replicated Blocks:

 Total size:	0 B

 Total files:	0

 Total blocks (validated):	0

 Minimally replicated blocks:	0

 Over-replicated blocks:	0

 Under-replicated blocks:	0

 Mis-replicated blocks:	0

 Default replication factor:	1

 Average block replication:	0.0

 Missing blocks:	0

 Corrupt blocks:	0

 Missing replicas:	0

 Blocks queued for replication:	0



Erasure Coded Block Groups:

 Total size:	0 B

 Total files:	0

 Total block groups (validated):	0

 Minimally erasure-coded block groups:	0

 Over-erasure-coded block groups:	0

 Under-erasure-coded block groups:	0

 Unsatisfactory placement block groups:	0

 Average block group size:	0.0

 Missing block groups:	0

 Corrupt block groups:	0

 Missing internal blocks:	0

 Blocks queued for replication:	0

FSCK ended at Tue Jul 12 21:30:51 KST 2022 in 0 milliseconds





The filesystem under path '/' is HEALTHY
```
_________________________________________________________________________________________________________________________________________________________________________
마지막으로 휴지통 사용법에 대해 말씀드리겠습니다.
_________________________________________________________________________________________________________________________________________________________________________
휴지통을 비우는 명령어는 다음과 같습니다. 경고 메세지 외에 아무것도 표시되지 않고 다시 명령어 입력 상태로 돌아오면 정상적으로 실행된 것으로 보시면 됩니다.
```
(base) shcDE-ui-MacBookPro:hadoop shc$ bin/hadoop fs -expunge
2022-07-12 21:36:14,551 WARN util.NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
(base) shcDE-ui-MacBookPro:hadoop shc$
```
_________________________________________________________________________________________________________________________________________________________________________
휴지통을 이용하지 않고 경로 직접 입력을 통해 삭제도 가능합니다. 이는 샘플 파일을 만들고 테스트를 하시길 추천드립니다.
```
$ bin/hadoop fs -rm -skipTrash (경로)
```
_________________________________________________________________________________________________________________________________________________________________________
이상으로 HDFS 휴지통까지 다루는 방법에 대해 배워봤습니다. 다음 포스팅에서는 HDFS 명령어 사용법에 대해 다루겠습니다.
_________________________________________________________________________________________________________________________________________________________________________
오늘도 긴 글 읽어주셔서 감사합니다. 해당 글은 위키독스의 ['빅데이터 - 하둡, 하이브로 시작하기'](https://wikidocs.net/book/2203) 문서를 바탕으로 작성되었습니다.
_________________________________________________________________________________________________________________________________________________________________________
[레퍼런스]
1. 빅데이터 - 하둡, 하이브로 시작하기(위키독스) : https://wikidocs.net/book/2203